{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913a3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87817911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc43d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6b1062",
   "metadata": {},
   "source": [
    "## Minsearch indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990f9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267f9429-4f31-4750-bdf4-84d0a3ec554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "minsearch_text_index = minsearch.Index(\n",
    "    text_fields=['Title', 'Instructions'], # 'Cleaned_Ingredients', 'Image_Name'],\n",
    "    keyword_fields=['Id'],\n",
    "    type='text'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d734c998-f4a5-4390-9708-6c1edda23348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x15789be50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_text_index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768cc1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641c8589930a4f478ff6ee1a727a69de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x157f00340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "minsearch_vector_index = minsearch.Index(\n",
    "    text_fields=['Title', 'Instructions'], # 'Cleaned_Ingredients', 'Image_Name'],\n",
    "    keyword_fields=['Id'],\n",
    "    model=model,\n",
    "    type='vector'\n",
    ")\n",
    "minsearch_vector_index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3767c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aca14f20ad64ec894a62b96ccb9c917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x175c68ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_hybrid_index = minsearch.Index(\n",
    "    text_fields=['Title', 'Instructions'], # 'Cleaned_Ingredients', 'Image_Name'],\n",
    "    keyword_fields=['Id'],\n",
    "    model=model,\n",
    "    type='hybrid'\n",
    ")\n",
    "minsearch_hybrid_index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ae51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c1d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en = model.encode('what do you cook?')\n",
    "X_en1 = model.encode('How do you cook?').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a23b3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en = X_en.reshape(1, -1)\n",
    "X_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "122fd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "results.append(X_en)\n",
    "#results.append(X_en1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cba92680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results = np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "046b5fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96a684",
   "metadata": {},
   "source": [
    "## Search with ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d221932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'recipe-questions' created\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "INDEX_NAME=\"recipe-questions\"\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"Title\": {\"type\": \"text\"},\n",
    "            \"Instructions\": {\"type\": \"text\"},\n",
    "            \"Cleaned_Ingredients\": {\"type\": \"text\"},\n",
    "            \"Image_Name\": {\"type\": \"text\"},\n",
    "            # \"Title\": {\"type\": \"keyword\"},\n",
    "            # \"Instructions\": {\"type\": \"keyword\"},\n",
    "            # \"Cleaned_Ingredients\": {\"type\": \"keyword\"},\n",
    "            # \"Image_Name\": {\"type\": \"keyword\"},\n",
    "            \"Id\": {\"type\": \"keyword\"},\n",
    "            # \"title_vector\": {\n",
    "            #     \"type\": \"dense_vector\",\n",
    "            #     \"dims\": 384, #768, #\n",
    "            #     \"index\": True,\n",
    "            #     \"similarity\": \"cosine\",\n",
    "            # },\n",
    "            # \"instr_vector\": {\n",
    "            #     \"type\": \"dense_vector\",\n",
    "            #     \"dims\": 384, #768, #\n",
    "            #     \"index\": True,\n",
    "            #     \"similarity\": \"cosine\",\n",
    "            # },\n",
    "            # \"ingr_vector\": {\n",
    "            #     \"type\": \"dense_vector\",\n",
    "            #     \"dims\": 384, #768, #\n",
    "            #     \"index\": True,\n",
    "            #     \"similarity\": \"cosine\",\n",
    "            # },\n",
    "            # \"instr_ingr_vector\": {\n",
    "            #     \"type\": \"dense_vector\",\n",
    "            #     \"dims\": 384, #768, #\n",
    "            #     \"index\": True,\n",
    "            #     \"similarity\": \"cosine\",\n",
    "            # },\n",
    "            \"title_instr_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384, #768, #\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "            # \"title_ingr_vector\": {\n",
    "            #     \"type\": \"dense_vector\",\n",
    "            #     \"dims\": 384, #768, #\n",
    "            #     \"index\": True,\n",
    "            #     \"similarity\": \"cosine\",\n",
    "            # },\n",
    "            \"title_instr_ingr_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384, #768, #\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es_client.indices.delete(index=INDEX_NAME, ignore_unavailable=True)\n",
    "es_client.indices.create(index=INDEX_NAME, body=index_settings)\n",
    "print(f\"Elasticsearch index '{INDEX_NAME}' created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a25b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document(es_client, doc, model):\n",
    "    title = doc[\"Title\"]\n",
    "    instructions = doc[\"Instructions\"]\n",
    "    ingredients = doc[\"Cleaned_Ingredients\"]\n",
    "    # doc[\"title_vector\"] = model.encode(title)\n",
    "    # doc[\"instr_vector\"] = model.encode(instructions)\n",
    "    # doc[\"ingr_vector\"] = model.encode(ingredients)\n",
    "    doc[\"title_instr_vector\"] = model.encode(title + \" \" + instructions).tolist()\n",
    "    # doc[\"title_ingr_vector\"] = model.encode(title + \" \" + ingredients).tolist()\n",
    "    # doc[\"instr_ingr_vector\"] = model.encode(instructions + \" \" + ingredients).tolist()\n",
    "    doc[\"title_instr_ingr_vector\"] = model.encode(title + \" \" + instructions + \" \" + ingredients).tolist()\n",
    "    es_client.index(index=INDEX_NAME, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6befec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f716b1fed6d400598398f54d4f6fad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "executor = ThreadPoolExecutor(8)\n",
    "\n",
    "with tqdm(total=len(documents)) as progress:\n",
    "        futures = []\n",
    "        for doc in documents:\n",
    "            future = executor.submit(index_document, es_client, doc, model)\n",
    "            # attaches a callback to the future that will update\n",
    "            # the progress bar each time a task is completed\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "        for future in futures:\n",
    "            # The code waits for each future to complete by calling future.result().\n",
    "            # This call  will block until the task is finished, and\n",
    "            # then it retrieves the result.\n",
    "            result = future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488485f6",
   "metadata": {},
   "source": [
    "### Elastic Search text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0da318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_text(query,  index_name=INDEX_NAME):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"Title\", \"Instructions\"],\n",
    "                        \"type\": \"most_fields\",\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583be8de",
   "metadata": {},
   "source": [
    "### ElasticSearch vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ba1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, index_name=INDEX_NAME):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"Image_Name\", \"Title\", \"Cleaned_Ingredients\", \"Instructions\", \"Id\"],\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd5af3",
   "metadata": {},
   "source": [
    "### ElasticSearch hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f86ad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(field, query, vector, index_name=INDEX_NAME):\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"Cleaned_Ingredients\", \"Title\", \"Instructions\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn_query,\n",
    "        \"query\": keyword_query,\n",
    "        \"size\": 5,\n",
    "        \"_source\": [\"Image_Name\", \"Title\", \"Cleaned_Ingredients\", \"Instructions\", \"Id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70bc03-575d-4576-8b1d-f82462feb485",
   "metadata": {},
   "source": [
    "## RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c0eef0c9-3e59-4b02-9f49-57f7ae78e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96687ff0-3348-4743-a56a-786127c84fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_text_search(query):\n",
    "    # boost = {'Cleaned_Ingredients': 2.0, 'Instructions': 4.0, 'Title': 1.0}\n",
    "    boost = {}\n",
    "    results = minsearch_text_index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def minsearch_vector_search(query):\n",
    "    # boost = {'Cleaned_Ingredients': 2.0, 'Instructions': 4.0, 'Title': 1.0}\n",
    "    #boost = {}\n",
    "    results = minsearch_vector_index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        #boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def minsearch_hybrid_search(query):\n",
    "    boost = {'Instructions': 3.0, 'Title': 2.0}\n",
    "    #boost = {}\n",
    "    results = minsearch_hybrid_index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        hybrid_boost={'text':0.5, 'vector':0.5},\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2450e48b-b4e3-4555-9e01-5674c3ff0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a well-known chief. Your goal is to provide recipes to users who can\n",
    "give you a list of ingredients or ask you about recipes. Answer the QUESTION based on the CONTEXT from our recipes database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION and always cite the title and the Image_Name\n",
    "Your answer must be in mardown format with an image displaying the food where Image_Name is the url.\n",
    "The url must have the following form : ../data/Food_Images/Image_Name.jpg\n",
    "\n",
    "If Image_Name is empty write that the image not available.\n",
    "\n",
    "The ingredients must come first before the instructions.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "entry_template = \"\"\"\n",
    "title: {Title}\n",
    "instructions: {Instructions}\n",
    "ingredients: {Cleaned_Ingredients}\n",
    "image_name: {Image_Name}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3881e794-a85b-4bd2-a9a0-ae5ab1021776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1d1c70-a21d-4af7-8168-22215303687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = minsearch_text_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c77a0a9e-3955-405f-8bff-66214f79e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can make **Hard-Boiled Eggs** with the ingredients you have. Here’s how:\n",
      "\n",
      "### Ingredients\n",
      "- 4–8 large eggs\n",
      "\n",
      "### Instructions\n",
      "1. Bring a large saucepan of water to a boil over medium-high heat. \n",
      "2. Using a slotted spoon, carefully lower eggs into the water one at a time. \n",
      "3. Cook for 10 minutes, maintaining a gentle boil. \n",
      "4. Carefully transfer the eggs to a bowl of ice water and let cool until just slightly warm, about 2 minutes. \n",
      "5. Gently crack the eggs all over and peel, starting from the fat end containing the air pocket. \n",
      "\n",
      "Eggs can be cooked and peeled 3 days ahead. Transfer to an airtight container and chill.\n",
      "\n",
      "![Hard-Boiled Eggs](../data/Food_Images/hard-boiled-eggs-recipe.jpg)\n"
     ]
    }
   ],
   "source": [
    "question = 'I have eggs, oinion, bread what can i cook?'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805ae3e",
   "metadata": {},
   "source": [
    "With the ingredients you have (eggs, onion, and bread), you can make **Egg and Onion Toast**. Here’s a simple recipe you can follow:\n",
    "\n",
    "### Ingredients:\n",
    "- **Eggs**: 2 (or more depending on how many servings you want)\n",
    "- **Onion**: 1 small, finely chopped\n",
    "- **Bread**: 2 slices (your choice, such as sourdough or whole wheat)\n",
    "- **Salt and pepper**: to taste\n",
    "- **Butter or oil**: for frying\n",
    "\n",
    "### Instructions:\n",
    "1. **Prepare the Ingredients**: Chop the onion finely.\n",
    "2. **Cook the Onion**: Heat a skillet over medium heat and add butter or oil. Once hot, add the chopped onion and sauté until caramelized and golden brown, about 5-7 minutes.\n",
    "3. **Cook the Eggs**: In the same skillet, crack the eggs directly over the sautéed onions (you can scramble them or cook them sunny-side up based on your preference). Season with salt and pepper.\n",
    "4. **Toast the Bread**: While the eggs are cooking, you can toast the bread slices in a separate toaster or in the same skillet if there’s room.\n",
    "5. **Assemble the Toast**: Once the eggs are cooked to your liking, serve them over the toasted bread topped with the sautéed onions. \n",
    "\n",
    "Enjoy your Egg and Onion Toast!\n",
    "\n",
    "![Egg and Onion Toast](../data/Food_Images/hard-boiled-eggs-recipe.jpg)\n",
    "Id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100bd80-431d-4990-98f7-0ef5ed0fd174",
   "metadata": {},
   "source": [
    "## Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88433ad-dcc1-4455-a0df-3006b43c52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6525af2-4c66-4f4a-88c2-91e0b6b8dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What type of chicken should I use for the Miso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How should I prepare the acorn squash before r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What herbs are used in the herb butter mixture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>How long does the chicken need to rest after r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>What type of wine is recommended for the gravy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           question\n",
       "0   1  What type of chicken should I use for the Miso...\n",
       "1   1  How should I prepare the acorn squash before r...\n",
       "2   1  What herbs are used in the herb butter mixture...\n",
       "3   1  How long does the chicken need to rest after r...\n",
       "4   1  What type of wine is recommended for the gravy..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e41a0aa-8f78-4aeb-b334-dd963d63a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86b03ae-5a68-4ac4-9314-00b521b56272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': 1,\n",
       " 'question': 'What type of chicken should I use for the Miso-Butter Roast Chicken With Acorn Squash Panzanella recipe?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad9e893-c880-4af5-b6df-4a9b2806d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde9bbdd-f1a3-4e73-8538-d2591ed159c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['Id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['Id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e150ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(q, search_function):\n",
    "\n",
    "    doc_id = q['Id']\n",
    "    results = search_function(q['question'])\n",
    "    relevance = [d['Id'] == doc_id for d in results]\n",
    "\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49033d89-9f85-4374-a379-28b4dd9ec14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "#max_workers=8\n",
    "pool = ThreadPoolExecutor(max_workers=8)\n",
    "\n",
    "def map_progress(pool, seq,search_function, f):\n",
    "\n",
    "    \"\"\"\n",
    "    The map_progress function essentially applies a given function f\n",
    "      to each element of a sequence seq in parallel using multiple threads,\n",
    "      while also displaying a progress bar to track how much of the work has\n",
    "      been completed. This can be useful when you have a large number of tasks\n",
    "      to process and want to speed up the work using concurrency,\n",
    "      while also having a visual indicator of progress.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            # For each element, the function f is submitted to the thread pool\n",
    "            # for execution with pool.submit(f, el). This returns a future,\n",
    "            # an object that  represents the result of the task that will be\n",
    "            # completed in the future.\n",
    "            future = pool.submit(f, el, search_function)\n",
    "            # attaches a callback to the future that will update\n",
    "            # the progress bar each time a task is completed\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            # The code waits for each future to complete by calling future.result().\n",
    "            # This call  will block until the task is finished, and\n",
    "            # then it retrieves the result.\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(results),\n",
    "        'mrr': mrr(results),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85f14d",
   "metadata": {},
   "source": [
    "### Evaluate minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e085a274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7790db89f49a4f32bc070ca8dafee0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6206503221983557, 'mrr': 0.4916421299774336}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_progress(pool, ground_truth, minsearch_text_search, evaluate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a68d0fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acc0c65cfba466aae5c1b480202bd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6240722909414117, 'mrr': 0.4914756343739321}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_progress(pool, ground_truth, minsearch_vector_search, evaluate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6210322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31ca6ca8ef943f5965a0997769ba5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6722168728242353, 'mrr': 0.5320085754964565}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_progress(pool, ground_truth, minsearch_hybrid_search, evaluate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a378852",
   "metadata": {},
   "source": [
    "### Evaluate elastic search text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f005bbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b8fa6c46d447c195bccb72a2cf3acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5364047107621658, 'mrr': 0.4308330247142114}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate(ground_truth, lambda q: elastic_search_text(q['question']))\n",
    "map_progress(pool, ground_truth, elastic_search_text, evaluate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e57096",
   "metadata": {},
   "source": [
    "### Evaluate elastic search vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23d006c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c821c9db4646ef997742bfd710c1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field instr_vector is: \n",
      " {'hit_rate': 0.2995926227686838, 'mrr': 0.21272103300991294}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdbff21a7f749a68906b53bbc3296f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field ingr_vector is: \n",
      " {'hit_rate': 0.1406118065328494, 'mrr': 0.08949633360491584}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e832c28cf51d4057905ac1899776a92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field instr_ingr_vector is: \n",
      " {'hit_rate': 0.3209095622546478, 'mrr': 0.22942152433154606}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248a947f591441b7986cc9a58139716b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field title_vector is: \n",
      " {'hit_rate': 0.5192504258943782, 'mrr': 0.4397284151791178}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef2c6dd7289457e9c5386c1e84ef558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field title_ingr_vector is: \n",
      " {'hit_rate': 0.525501814680394, 'mrr': 0.43574401896155385}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b42358a6c54c1892953b8a8fdb4a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field title_instr_vector is: \n",
      " {'hit_rate': 0.5677801644322643, 'mrr': 0.4774441399402419}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c6d4d0a9e44edbaca56f6b59fa0b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field title_instr_ingr_vector is: \n",
      " {'hit_rate': 0.5644026368417154, 'mrr': 0.4744791743821372}\n"
     ]
    }
   ],
   "source": [
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('instr_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field instr_vector is: \\n {v_i}\")\n",
    "\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('ingr_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field ingr_vector is: \\n {v_i}\")\n",
    "\n",
    "\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('instr_ingr_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field instr_ingr_vector is: \\n {v_i}\")\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('title_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field title_vector is: \\n {v_i}\")\n",
    "\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('title_ingr_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field title_ingr_vector is: \\n {v_i}\")\n",
    "\n",
    "v_i = evaluate(ground_truth, lambda q: elastic_search_knn('title_instr_vector', model.encode(q['question'])))\n",
    "print (f\"the search evaluation for the field title_instr_vector is: \\n {v_i}\")\n",
    "\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_knn('title_instr_ingr_vector', model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field title_instr_ingr_vector is: \\n {v_i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a967001",
   "metadata": {},
   "source": [
    "### Evaluate elastic search hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50970c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6914a888dec94e04aaed27a4305a7e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field instr_vector is: \n",
      " {'hit_rate': 0.3245092956077328, 'mrr': 0.2324835197392945}\n",
      "{'hit_rate': 0.3214872972372417, 'mrr': 0.22995012715109064}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c4e1a45234028bb7755e99bc8dcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field ingr_vector is: \n",
      " {'hit_rate': 0.3227020220724391, 'mrr': 0.23125595634892787}\n",
      "{'hit_rate': 0.3214872972372417, 'mrr': 0.22995012715109064}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78659917ba834ca99c46ec89df4645a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the search evaluation for the field instr_ingr_vector is: \n",
      " {'hit_rate': 0.32490926598029773, 'mrr': 0.23273683430858574}\n",
      "{'hit_rate': 0.3214872972372417, 'mrr': 0.22995012715109064}\n"
     ]
    }
   ],
   "source": [
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_hybrid('instr_vector',q['question'], model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field instr_vector is: \\n {v_i}\")\n",
    "# print(_)\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_hybrid('ingr_vector',q['question'], model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field ingr_vector is: \\n {v_i}\")\n",
    "# print(_)\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_hybrid('instr_ingr_vector',q['question'], model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field instr_ingr_vector is: \\n {v_i}\")\n",
    "# print(_)\n",
    "\n",
    "v_i = evaluate(ground_truth, lambda q: elastic_search_hybrid('title_instr_vector',q['question'], model.encode(q['question'])))\n",
    "print (f\"the search evaluation for the field title_instr_ingr_vector is: \\n {v_i}\")\n",
    "\n",
    "# v_i = evaluate(ground_truth, lambda q: elastic_search_hybrid('title_instr_ingr_vector',q['question'], model.encode(q['question'])))\n",
    "# print (f\"the search evaluation for the field title_instr_ingr_vector is: \\n {v_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137144-7060-4e4c-aba5-359de3085144",
   "metadata": {},
   "source": [
    "## Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "387e641c-6592-4e4f-b191-1e5ca7598f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_sample = df_question.sample(frac=1)\n",
    "df_validation = df_q_sample[:30000]\n",
    "df_test = df_question[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a95c044-df61-4cb6-84a9-19ff9e1ef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "\n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "\n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6535225c-aa11-4875-895e-f84f2020083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33d2c962-b56a-4f1d-892a-1b84e89f4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_hybrid_search(query, boost=None, hybrid_boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    if hybrid_boost is None:\n",
    "        hybrid_boost = {'text':0.5, 'vector':0.5}\n",
    "\n",
    "\n",
    "    results = minsearch_hybrid_index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        hybrid_boost=hybrid_boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "157ebfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(q, search_function):\n",
    "\n",
    "    doc_id = q['Id']\n",
    "    results = search_function(q)\n",
    "    relevance = [d['Id'] == doc_id for d in results]\n",
    "\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d61d688-45a0-40c9-bf5a-e87ad778ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "param_ranges = {\n",
    "    'Title': (0.0, 3.0),\n",
    "    'Instructions': (0.0, 3.0),\n",
    "    'text': (0.0, 1.0),\n",
    "    # 'Cleaned_Ingredients': (0.0, 3.0),\n",
    "    # 'Image_Name': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params:Dict[str, float]):\n",
    "    params = boost_params.copy()\n",
    "    text_boost = params.pop('text')\n",
    "    def search_function(q):\n",
    "        return minsearch_hybrid_search(q['question'], params, hybrid_boost={'text': text_boost, 'vector': 1-text_boost})\n",
    "\n",
    "    # results = evaluate(gt_val, search_function)\n",
    "    results = map_progress(pool, gt_val, search_function, evaluate2)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85f903c6-9c07-4399-9cca-e12bda23e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2edef89f29d460a91defe70f42f971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc4f44236d4154bd915e1e25aba0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e0d3b853fd4725849861d774f5138d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b323dcf6f2ff4277aea6c681ad676580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ef6df6f7ed4bde8320362dcc8184d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b5e17277246f0b2462fb863e467f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8539c76c8a4dcf85fdee78daaa6950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b71f50e2a245db936e698c7813f9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c7cb9a1e6c4d389385c10dfbfbf7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d343adb1243246dd80d82ed67651a242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b012f97288945ff963b0d27fecdb586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81171dfb1778472eb41a36a88f3cae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94111faf6c14c8ea19ec06c823e4700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddee7d4653344838db768890495964c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9544a713920e403bb5c0f965b93c5075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fce4c8733bc4630b2133392355173fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f119bbde2f4721967e6a2778f38752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9ac84e34e48e18c2c9ee56c5c4e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbe35e754c04f0ea89b4cdf10dbd3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f482dd166cc499787cb4e40573e1547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Title': 1.301766512843531,\n",
       "  'Instructions': 0.7387164179150028,\n",
       "  'text': 0.36555723393033346},\n",
       " 0.5693462169312256)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e11a1b9-9375-4c24-bfb3-0170ce82187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede7a64823d245e484c4d8be6156e841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6847640915487742, 'mrr': 0.5694318527845589}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_hybrid_improved(query):\n",
    "    boost = {\n",
    "  'Title': 1.301766512843531,\n",
    "  'Instructions': 0.7387164179150028,\n",
    "  'text': 0.36555723393033346\n",
    "#   'Cleaned_Ingredients': 1.3020399036175552,\n",
    "#   'Image_Name': 1.7024187651904266\n",
    "    }\n",
    "\n",
    "    text = boost.pop('text')\n",
    "\n",
    "    results = minsearch_hybrid_index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        hybrid_boost={'text':text, 'vector': 1-text},\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "map_progress(pool, ground_truth, minsearch_hybrid_improved, evaluate1)\n",
    "#evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d231bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('index.pkl', 'wb') as ind:\n",
    "    pickle.dump(minsearch_hybrid_index, ind, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3bfba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.pkl', 'rb') as ind:\n",
    "    index = pickle.load(ind)\n",
    "\n",
    "def minsearch_hybrid_improved(query):\n",
    "    boost = {\n",
    "  'Title': 1.301766512843531,\n",
    "  'Instructions': 0.7387164179150028,\n",
    "  'text': 0.36555723393033346\n",
    "#   'Cleaned_Ingredients': 1.3020399036175552,\n",
    "#   'Image_Name': 1.7024187651904266\n",
    "    }\n",
    "\n",
    "    text = boost.pop('text')\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        hybrid_boost={'text':text, 'vector': 1-text},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7875792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Id': 11281,\n",
       "  'Title': 'Hard-Boiled Eggs',\n",
       "  'Instructions': '1. \\x07  Put eggs into a 1-quart saucepan, then add enough cold water to cover them by 1/2 inch. Bring water to a boil over high heat, then reduce heat to moderately high and cook eggs at a gentle boil, uncovered, 10 minutes. Pour off hot water. If using eggs right away, shake pan gently so eggs bump into one another (to crack shells). Run cold water into pot to stop cooking. Let eggs stand in cold water 15 minutes, adding more cold water or ice to keep water cold.\\n\\n',\n",
       "  'Ingredients': '*\\x08  4 large eggs\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  4 large eggs\\n',\n",
       "  'Image_Name': 'hard-boiled-eggs-236719'},\n",
       " {'Id': 2092,\n",
       "  'Title': 'Hard-Boiled Eggs',\n",
       "  'Instructions': '1. \\x07  Bring a large saucepan of water to a boil over medium-high heat. Using a slotted spoon, carefully lower eggs into water one at a time. Cook 10 minutes, maintaining a gentle boil. Carefully transfer eggs to a bowl of ice water and let cool until just slightly warm, about 2 minutes.\\n\\n2. \\x07  Gently crack eggs all over and peel, starting from the fat end containing the air pocket.\\n\\n3. \\x07  Eggs can be cooked and peeled 3 days ahead. Transfer to an airtight container and chill.\\n\\n',\n",
       "  'Ingredients': '*\\x08  4–8 large eggs\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  4–8 large eggs\\n',\n",
       "  'Image_Name': 'hard-boiled-eggs-recipe'},\n",
       " {'Id': 768,\n",
       "  'Title': 'Big-Batch Hard-Boiled Eggs',\n",
       "  'Instructions': '1. \\x07  Fill a large pot with 1\" water and fit a steamer basket into pot. Cover and bring to a boil over high heat. Carefully place eggs in steamer basket. Cover with a tight-fitting lid and steam 12 minutes.\\n\\n2. \\x07  Using tongs, immediately transfer eggs to a large bowl filled with ice water to stop cooking. Let sit until cool enough to handle, about 10 minutes. Peel.\\n\\n3. \\x07  Do Ahead: Eggs can be steamed and peeled 1 week ahead. Store in an airtight container and chill.\\n\\n',\n",
       "  'Ingredients': '*\\x08  24 large eggs\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  24 large eggs\\n',\n",
       "  'Image_Name': 'big-batch-hard-boiled-eggs'},\n",
       " {'Id': 1462,\n",
       "  'Title': 'Instant Pot Hard-Boiled Eggs',\n",
       "  'Instructions': '1. \\x07  Pour the water into the Instant Pot and place a steamer basket or the trivet into the pot. Gently place up to 12 eggs into the basket or on top of the trivet, taking care not to crack the eggs as you add them. Secure the lid and set the Pressure Release to Sealing. Select the Manual setting and set the cooking time for 5 minutes at high pressure.\\n\\n2. \\x07  While the eggs are cooking, prepare an ice bath. When the timer goes off, let the pressure release naturally for 5 minutes, then move the Pressure Release to Venting to release the remaining steam. Open the pot and transfer the eggs to the ice bath to cool. Peel when ready to serve.\\n\\n3. \\x07  Pour the water into the Instant Pot and place a steamer basket or the trivet into the pot. Gently place up to 12 eggs into the basket or on top of the trivet, taking care not to crack the eggs as you add them. Secure the lid and set the Pressure Release to Sealing. Select the Manual setting and set the cooking time for 2 minutes at high pressure.\\n\\n4. \\x07  While the eggs are cooking, prepare an ice bath. When the timer goes off, let the pressure release naturally for 15 minutes, then move the Pressure Release to Venting to release any remaining steam. Open the pot and transfer the eggs to the ice bath to cool. Peel when ready to serve.\\n\\n',\n",
       "  'Ingredients': '*\\x08  1 cup water\\n*\\x08  Up to 12 large eggs, straight from the refrigerator\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  1 cup water\\n*\\x08  Up to 12 large eggs\\n*\\x08  straight from the refrigerator\\n',\n",
       "  'Image_Name': 'instant-pot-hard-boiled-eggs'},\n",
       " {'Id': 10695,\n",
       "  'Title': 'Easy Egg Custard',\n",
       "  'Instructions': '1. \\x07  1. Preheat oven to 300°F.\\n\\n2. \\x07  2. Place six 4-ounce ovenproof cups (you can use ramekins, or coffee cups marked as oven-safe) in a deep baking pan just large enough to hold them.\\n\\n3. \\x07  3. In a medium saucepan, bring the milk to a simmer over medium-low heat.\\n\\n4. \\x07  4. Meanwhile, in a separate bowl, whisk together the eggs, yolks, sugar, and vanilla.\\n\\n5. \\x07  5. Slowly pour the egg mixture into the simmering milk, whisking gently to combine.\\n\\n6. \\x07  6. Pour the mixture through a fine strainer into the cups (if the strainer clogs, use a spoon to scrape it clean), then sprinkle lightly with the nutmeg.\\n\\n7. \\x07  7. Pour hot (not boiling) water into the pan until it reaches halfway up the sides of the cups.\\n\\n8. \\x07  8. Bake until the custard is just set (it can still be a little loose), 30 to 35 minutes.\\n\\n9. \\x07  9. Let the custard cool in the water bath for about 2 hours before serving.\\n\\n',\n",
       "  'Ingredients': '*\\x08  2 cups whole milk\\n*\\x08  2 eggs (preferably free-range)\\n*\\x08  2 egg yolks\\n*\\x08  1/3 cup sugar\\n*\\x08  1 teaspoon vanilla extract\\n*\\x08  Freshly grated or ground nutmeg\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  2 cups whole milk\\n*\\x08  2 eggs (preferably free-range)\\n*\\x08  2 egg yolks\\n*\\x08  1/3 cup sugar\\n*\\x08  1 teaspoon vanilla extract\\n*\\x08  Freshly grated or ground nutmeg\\n',\n",
       "  'Image_Name': 'easy-egg-custard-239229'},\n",
       " {'Id': 5671,\n",
       "  'Title': 'Egg in the Middle',\n",
       "  'Instructions': \"1. \\x07  First stamp a circle from the center of each slice of bread with a 2-inch cookie cutter and reserve.\\n\\n2. \\x07  Heat 2 tablespoons of the oil in a frying pan or skillet over medium heat, add the bread and reserved rounds ('hats') and fry until the undersides are lightly golden.\\n\\n3. \\x07  Turn the bread over, adding more oil if necessary.\\n\\n4. \\x07  Carefully break the eggs and ease them into the holes. (Sometimes I drain off a little of the white, but this is not a rule.)\\n\\n5. \\x07  Reduce the heat and cook until the whites are set and the yolks are beginning to set, but are still soft.\\n\\n6. \\x07  Using a spatula, transfer the slices of bread and eggs to a plate, with their hats over the yolks, and serve.\\n\\n\",\n",
       "  'Ingredients': '*\\x08  2 slices bread, preferably whole wheat\\n*\\x08  2-3 tablespoons olive oil\\n*\\x08  2 eggs\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  2 slices bread, preferably whole wheat\\n*\\x08  2-3 tablespoons olive oil\\n*\\x08  2 eggs\\n',\n",
       "  'Image_Name': 'egg-in-the-middle-51150000'},\n",
       " {'Id': 6555,\n",
       "  'Title': 'Scotch Egg',\n",
       "  'Instructions': '1. \\x07  Place 4 eggs in a small saucepan; add cold water to cover. Bring to a boil; remove from heat, cover, and let stand for 3 minutes. Carefully drain, then fill pan with ice water to cool eggs. Gently crack shells and carefully peel under cold running water. Place eggs in a bowl of cold water; cover and chill until cold. DO AHEAD: Can be made 1 day ahead. Keep chilled.\\n\\n2. \\x07  Place flour in a wide shallow bowl and crushed corn flakes in another wide shallow bowl. Divide sausage into 4 equal portions. Pat 1 portion of sausage into a thin patty over the length of your palm. Lay 1 soft-boiled egg on top of sausage and wrap sausage around egg, sealing to completely enclose. Repeat with remaining sausage and eggs.\\n\\n3. \\x07  Whisk remaining 2 eggs in a medium bowl to blend. Working gently with 1 sausage wrapped egg at a time, dip eggs into flour, shaking off excess, then coat in egg wash. Roll in corn flakes to coat. DO AHEAD: Can be made 1 day ahead. Keep refrigerated, uncovered.\\n\\n4. \\x07  Attach a deep-fry thermometer to side of a large heavy pot. Pour in oil to a depth of 2\" and heat over medium heat to 375°F. Fry eggs, turning occasionally and maintaining oil temperature of 350°F, until sausage is cooked through and breading is golden brown and crisp, 5-6 minutes. Use a slotted spoon to transfer eggs to paper towels to drain. Season lightly with salt and pepper. Serve warm with mustard.\\n\\n',\n",
       "  'Ingredients': '*\\x08  6 large eggs\\n*\\x08  1 cup all-purpose flour\\n*\\x08  1 cup finely crushed corn flakes\\n*\\x08  7 ounces (3/4 cup) fresh breakfast sausage, casings removed (if necessary)\\n*\\x08  Vegetable oil (for frying)\\n*\\x08  Kosher salt, freshly ground pepper\\n*\\x08  Mustard\\n*\\x08  A deep-fry thermometer\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  6 large eggs\\n*\\x08  1 cup all-purpose flour\\n*\\x08  1 cup finely crushed corn flakes\\n*\\x08  7 ounces (3/4 cup) fresh breakfast sausage, casings removed (if necessary)\\n*\\x08  Vegetable oil (for frying)\\n*\\x08  Kosher salt, freshly ground pepper\\n*\\x08  Mustard\\n*\\x08  A deep-fry thermometer\\n',\n",
       "  'Image_Name': 'scotch-egg-380611'},\n",
       " {'Id': 5319,\n",
       "  'Title': 'Spicy Bacon and Egg',\n",
       "  'Instructions': '1. \\x07  In a medium pan over high heat, heat 1 tablespoon oil. Cook two eggs until edges start to brown, 45 seconds. Break yolks; cook 15 seconds; flip.\\n\\n2. \\x07  Season each egg with 2 teaspoons Tabasco and black pepper. Top each egg with 1 slice cheese; cook until cheese melts and egg edges are crispy, 40 seconds. Remove eggs from pan; set aside. Repeat with remaining oil and eggs.\\n\\n3. \\x07  Cook bacon in batches, flipping once, until crispy, 2 minutes per side. Place bacon on a paper towel-lined plate. In a bowl, whisk together mayo and adobo; spread on toast slices.\\n\\n4. \\x07  Divide bacon, cheesy eggs, tomato and cabbage among 4 toast slices; top with remaining slices.\\n\\n',\n",
       "  'Ingredients': '*\\x08  2 tablespoons olive oil, divided\\n*\\x08  4 eggs\\n*\\x08  8 teaspoons Tabasco, divided\\n*\\x08  4 slices reduced-fat pepper jack cheese with habaneros\\n*\\x08  8 slices turkey bacon\\n*\\x08  4 tablespoons lowfat mayonnaise\\n*\\x08  2 tablespoons adobo sauce\\n*\\x08  8 slices whole-grain toast\\n*\\x08  2 medium vine-ripened tomatoes, thinly sliced\\n*\\x08  2 cups shredded Napa cabbage, divided\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  2 tablespoons olive oil, divided\\n*\\x08  4 eggs\\n*\\x08  8 teaspoons Tabasco, divided\\n*\\x08  4 slices reduced-fat pepper jack cheese with habaneros\\n*\\x08  8 slices turkey bacon\\n*\\x08  4 tablespoons lowfat mayonnaise\\n*\\x08  2 tablespoons adobo sauce\\n*\\x08  8 slices whole-grain toast\\n*\\x08  2 medium vine-ripened tomatoes, thinly sliced\\n*\\x08  2 cups shredded Napa cabbage\\n*\\x08  divided\\n',\n",
       "  'Image_Name': 'spicy-bacon-and-egg-51183610'},\n",
       " {'Id': 866,\n",
       "  'Title': 'Egg and Merguez Wraps',\n",
       "  'Instructions': '1. \\x07  Bring a medium pot of water to a boil. Carefully slip in eggs and cook 8 minutes. Transfer to a bowl of ice water with a slotted spoon; let cool. Peel eggs, then slice each crosswise into 5 pieces.\\n\\n2. \\x07  Meanwhile, mix yogurt, lemon juice, and garlic in a small bowl; season yogurt sauce with salt.\\n\\n3. \\x07  Heat oil in a large skillet over medium-high. Add sausage and press down on it with a wooden spoon or heatproof rubber spatula to flatten; cook, undisturbed, until browned underneath, about 4 minutes. Turn sausage over; break into smaller pieces with spoon. Cook until cooked through and crisp, about 3 minutes. Transfer sausage along with drippings to a medium bowl. Reserve skillet.\\n\\n4. \\x07  Lay out lavash on a work surface. Spread 1/4 cup yogurt sauce over each, leaving a 1\" border. Top with sausage, dividing evenly. Top each with 10 egg slices in a single layer, then with red onion, pickles, and mint. Fold in 2 sides of lavash and, starting at an unfolded edge, roll up tightly.\\n\\n5. \\x07  Set reserved skillet over medium heat and cook 2 wraps, undisturbed, until golden brown and starting to crisp underneath, about 2 minutes. Turn over and cook until golden brown and starting to crisp on the other side. Transfer to a cutting board. Repeat with remaining wraps. Cut wraps in half crosswise.\\n\\n',\n",
       "  'Ingredients': '*\\x08  8 large eggs\\n*\\x08  1 cup plain whole-milk Greek yogurt\\n*\\x08  2 Tbsp. fresh lemon juice\\n*\\x08  1 garlic clove, finely grated\\n*\\x08  Kosher salt\\n*\\x08  2 Tbsp. extra-virgin olive oil\\n*\\x08  1 lb. merguez sausage, casings removed\\n*\\x08  4 lavash or large flour tortillas\\n*\\x08  1/2 small red onion, halved, thinly sliced\\n*\\x08  4 dill pickles, sliced crosswise 1/4\" thick\\n*\\x08  3 cups mint leaves\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  8 large eggs\\n*\\x08  1 cup plain whole-milk Greek yogurt\\n*\\x08  2 Tbsp. fresh lemon juice\\n*\\x08  1 garlic clove, finely grated\\n*\\x08  Kosher salt\\n*\\x08  2 Tbsp. extra-virgin olive oil\\n*\\x08  1 lb. merguez sausage, casings removed\\n*\\x08  4 lavash or large flour tortillas\\n*\\x08  1/2 small red onion, halved, thinly sliced\\n*\\x08  4 dill pickles, sliced crosswise 1/4\" thick\\n*\\x08  3 cups mint leaves\\n',\n",
       "  'Image_Name': 'egg-and-merguez-wraps'},\n",
       " {'Id': 374,\n",
       "  'Title': 'Spinach and Egg Dumplings',\n",
       "  'Instructions': \"1. \\x07  Bring a medium pot of water to a boil over high heat. Add the spinach and cook for 30 seconds, until it turns a vivid green, then, using a slotted spoon, transfer it to a bowl of ice water. Chill thoroughly and drain. Wrap the spinach in a clean cheesecloth or tea towel to wring out excess moisture, then roughly chop it and set it aside.\\n\\n2. \\x07  In a small bowl, whisk together the eggs, milk, and ¼ teaspoon of the salt and set aside. In a medium nonstick skillet, heat the vegetable oil over medium-low heat until a few drops of water added to the pan sizzle and evaporate. Pour in the egg mixture and cook, stirring occasionally, for 4 minutes, just until the eggs form fluffy curds but have not fully set; they should still be slightly runny. Remove from the heat and let cool in a medium bowl.\\n\\n3. \\x07  Use your hands to gently fold the eggs, sesame oil, oyster sauce, remaining 1¼ teaspoons of salt, and pepper together until fully combined. Gently fold in the spinach and mix until fully incorporated.\\n\\n4. \\x07  Bring a large pot of water to a boil. Meanwhile, make the dumplings. Holding a wrapper in your palm, use a fork to add about 1 tablespoon of the filling to the center of the wrapper, then lightly pat down the filling with the fork to get rid of any air bubbles.\\n\\n5. \\x07  Fold the dumpling into the round yuan bao shape: Cradle the wrapper in your hands and fold the edge closest to you over the filling. Lightly squeeze the dumpling to push out any air bubbles. Clasp one end of the dumpling between your thumb and index finger to pinch it shut; repeat on the other side of the dumpling. Cradle the dumpling in your palms, clasping the sealed edge between your thumbs and index fingers, and squeeze it shut while pushing inward, making sure to squeeze out any air bubbles. The dumpling's belly should form a teardrop shape between your thumbs, which will create the yuan bao shape. Inspect the dumpling for any fissures that could rupture during cooking and pinch them shut. Repeat with the rest of the wrappers.\\n\\n6. \\x07  Working in batches, add the dumplings to the pot, 6 at a time. Boil for 2 minutes on high, then reduce the heat to medium-high and cook for 1 minute, then reduce the heat again to medium and cook for 2 more minutes. The dumplings are ready a minute or so after they rise to the surface; their skins will turn puffy. Using a slotted spoon, gently transfer the dumplings to a plate and serve immediately. Bring the water back to a boil over high heat and repeat with the remaining dumplings.\\n\\n\",\n",
       "  'Ingredients': '*\\x08  3 ounces spinach (ideally Chinese water spinach; about 2 cups packed)\\n*\\x08  8 large eggs\\n*\\x08  2½ tablespoons skim milk\\n*\\x08  1½ teaspoons kosher salt\\n*\\x08  2 tablespoons vegetable oil\\n*\\x08  1 teaspoon sesame oil\\n*\\x08  1 teaspoon oyster sauce\\n*\\x08  1 teaspoon freshly ground black pepper\\n*\\x08  24 Boiled Dumpling Wrappers\\n',\n",
       "  'Cleaned_Ingredients': '*\\x08  3 ounces spinach (ideally Chinese water spinach; about 2 cups packed)\\n*\\x08  8 large eggs\\n*\\x08  2½ tablespoons skim milk\\n*\\x08  1½ teaspoons kosher salt\\n*\\x08  2 tablespoons vegetable oil\\n*\\x08  1 teaspoon sesame oil\\n*\\x08  1 teaspoon oyster sauce\\n*\\x08  1 teaspoon freshly ground black pepper\\n*\\x08  24 Boiled Dumpling Wrappers\\n',\n",
       "  'Image_Name': 'spinach-and-egg-dumplings-dumpling-galaxy-recipe'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_hybrid_improved('How to cook boiled egg?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de669d5-f9a4-4da0-b533-2781204ece3b",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ab3ae9a-8639-4244-ada3-90d321f0ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb3a0f2a-a232-4864-bf43-c93578667914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67505"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2be59fd-2d38-4aeb-a335-025dc1cab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ecbac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = minsearch_hybrid_improved(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4b52632",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How to cook boiled egg?'\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f1a5c96-6904-4cd6-8f36-4c6f56ead161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To cook boiled eggs, you can choose from a few different methods. Below is a simple recipe for hard-boiled eggs.\n",
      "\n",
      "### Ingredients\n",
      "- 4 large eggs\n",
      "\n",
      "### Instructions\n",
      "1. Put the eggs into a 1-quart saucepan, then add enough cold water to cover them by 1/2 inch. \n",
      "2. Bring the water to a boil over high heat, then reduce heat to moderately high and cook the eggs at a gentle boil, uncovered, for 10 minutes. \n",
      "3. Pour off the hot water. If using the eggs right away, shake the pan gently so the eggs bump into one another (to crack the shells).\n",
      "4. Run cold water into the pot to stop the cooking process. Let the eggs stand in the cold water for 15 minutes, adding more cold water or ice to keep the water cold.\n",
      "\n",
      "![Hard-Boiled Eggs](../data/Food_Images/hard-boiled-eggs-236719.jpg) \n",
      "\n",
      "This recipe is titled \"Hard-Boiled Eggs\", and you can find the image [here](../data/Food_Images/hard-boiled-eggs-236719.jpg).\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "311e3d42-30a4-4fe7-906c-c3806442bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: How to cook boiled egg?\n",
      "Generated Answer: To cook boiled eggs, you can choose from a few different methods. Below is a simple recipe for hard-boiled eggs.\n",
      "\n",
      "### Ingredients\n",
      "- 4 large eggs\n",
      "\n",
      "### Instructions\n",
      "1. Put the eggs into a 1-quart saucepan, then add enough cold water to cover them by 1/2 inch. \n",
      "2. Bring the water to a boil over high heat, then reduce heat to moderately high and cook the eggs at a gentle boil, uncovered, for 10 minutes. \n",
      "3. Pour off the hot water. If using the eggs right away, shake the pan gently so the eggs bump into one another (to crack the shells).\n",
      "4. Run cold water into the pot to stop the cooking process. Let the eggs stand in the cold water for 15 minutes, adding more cold water or ice to keep the water cold.\n",
      "\n",
      "![Hard-Boiled Eggs](../data/Food_Images/hard-boiled-eggs-236719.jpg) \n",
      "\n",
      "This recipe is titled \"Hard-Boiled Eggs\", and you can find the image [here](../data/Food_Images/hard-boiled-eggs-236719.jpg).\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c081e711-4e5c-4cd4-bc8d-79a29c1f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6da1bf76-7670-4723-847d-15aad4a5d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "98a38031-1e2b-4134-bc88-6d9e857771f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a142e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from openai import OpenAI\n",
    "\n",
    "client_groq = Groq()\n",
    "client_openai = OpenAI()\n",
    "\n",
    "def llm(prompt, client, model='gemma2-9b-it'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query, client, model='gpt-4o-mini'):\n",
    "    search_results = minsearch_hybrid_improved(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, client, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a66cdc62-803c-4c79-a687-581788fe1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_evaluation(record, prompt, client_llm, client_eval, model_llm, model_eval):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, client_llm, model_llm)\n",
    "\n",
    "    prompt1 = prompt.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt1, client_eval, model_eval)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    return (record, answer_llm, evaluation)\n",
    "\n",
    "# evaluations = []\n",
    "\n",
    "\n",
    "def evaluation_func (documents, prompt, client_llm, client_eval, model_llm, model_eval):\n",
    "    executor = ThreadPoolExecutor(8)\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(documents)) as progress:\n",
    "        futures = []\n",
    "        for doc in documents:\n",
    "            future = executor.submit(build_evaluation, doc, prompt, client_llm, client_eval, model_llm, model_eval)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "# for record in tqdm(sample):\n",
    "#     question = record['question']\n",
    "#     answer_llm = rag(question)\n",
    "\n",
    "#     prompt = prompt2_template.format(\n",
    "#         question=question,\n",
    "#         answer_llm=answer_llm\n",
    "#     )\n",
    "\n",
    "#     evaluation = llm(prompt)\n",
    "#     evaluation = json.loads(evaluation)\n",
    "\n",
    "#     evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_gpt_o_mini = evaluation_func (sample, prompt2_template, client_llm=client_openai, client_eval=client_openai, model_llm='gpt-4o-mini', model_eval='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf61170e-bfde-4889-8cd3-98fbfcc89918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_evaluation(evaluations, model_name):\n",
    "\n",
    "    df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "    df_eval['id'] = df_eval.record.apply(lambda d: d['Id'])\n",
    "    df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "    df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "    df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "    del df_eval['record']\n",
    "    del df_eval['evaluation']\n",
    "    print (f\" Evaluation of {model_name} \\n : {df_eval.relevance.value_counts(normalize=True)}\")\n",
    "    df_eval.to_csv(f'../data/rag-eval-{model_name}.csv', index=False)\n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87007d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations = evaluation_func (sample, prompt2_template,'gemma2-9b-it')\n",
    "evaluations_mixtral_8x7b_32768 = []\n",
    "for record in tqdm(sample):\n",
    "    result = build_evaluation(record, prompt2_template, client_llm=client_groq, client_eval=client_openai, model_llm='mixtral-8x7b-32768', model_eval='gpt-4o-mini')\n",
    "\n",
    "    evaluations_mixtral_8x7b_32768.append(result)\n",
    "\n",
    "save_evaluation(evaluations_mixtral_8x7b_32768, 'mixtral-8x7b-32768')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_zoomcamp",
   "language": "python",
   "name": "llm_zoomcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
